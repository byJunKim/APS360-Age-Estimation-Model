{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Accuracy_Module.py\n",
    "%run DataLoading.py\n",
    "%run load_and_organize_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install p7zip-full\n",
    "!p7zip -d UTKFace.tar.gz\n",
    "!tar -xvf UTKFace.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = 'UTKFace/'\n",
    "out_path = 'Data/'\n",
    "\n",
    "count = organize_files(in_path, out_path, 1, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 95 # Make 1 for regression, 95 for classification\n",
    "\n",
    "VGG_classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 4096),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(4096, 1024),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(1024, num_classes),\n",
    "#     nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=False)\n",
    "vgg16.classifier = VGG_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace feature weights with those from vgg_face and update state_dict key names\n",
    "pre_trained = torch.load(\"vgg_face_dag.pth\")\n",
    "new = list(pre_trained.items())\n",
    "state_dict = vgg16.state_dict()\n",
    "\n",
    "count = 0\n",
    "for key, value in state_dict.items():\n",
    "    if(key.split('.')[0] == \"features\"):\n",
    "        layer_name, weights = new[count]      \n",
    "        state_dict[key] = weights\n",
    "        count += 1\n",
    "\n",
    "vgg16.load_state_dict(state_dict)\n",
    "vgg16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, data_loader, criterion):\n",
    "    total_epoch = 0\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in data_loader:\n",
    "        outputs = net(inputs.cuda())\n",
    "        loss = criterion(outputs.cuda(), labels.long().cuda())\n",
    "        total_loss += loss.item()\n",
    "        total_epoch += len(labels)\n",
    "        \n",
    "    return total_loss/total_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_outputs):\n",
    "    pred = []\n",
    "    smax = nn.Softmax(dim=1)\n",
    "    prob = smax(model_outputs)\n",
    "    \n",
    "    for i in range(prob.shape[0]):\n",
    "        temp = torch.Tensor([(v+1)*k if k > 1e-6 else 0 for v,k in enumerate(prob[i])])\n",
    "        temp = temp.sum()\n",
    "        pred.append(temp)\n",
    "        \n",
    "    return torch.Tensor(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(net, data):\n",
    "    c=0\n",
    "    mean = 0.0\n",
    "    for imgs, labels in data:\n",
    "        mean += labels.sum()\n",
    "        c+=32\n",
    "    mean = (mean/c).float()\n",
    "    \n",
    "    ss_reg = 0\n",
    "    ss_total = 0\n",
    "    \n",
    "    for imgs, labels in data:\n",
    "        labels = labels.float() + 1\n",
    "        output = net(imgs.cuda())\n",
    "        pred = predict(output)\n",
    "        \n",
    "        ss_reg += ((labels - pred)**2).sum()\n",
    "        ss_total += ((labels - mean)**2).sum()\n",
    "    \n",
    "    return 1 - ss_reg/ss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_off_accuracy(net, data_loader):\n",
    "    freq_pos = np.zeros(81)\n",
    "    freq_neg = np.zeros(80)\n",
    "    \n",
    "    for img, label in data_loader:\n",
    "        out = net(img.cuda())\n",
    "        pred = predict(out)\n",
    "        pred = pred.float()\n",
    "             \n",
    "        for i in range(0, len(label)):\n",
    "            diff = label[i] + 1 - pred[i].long()\n",
    "            \n",
    "            if diff >= 0:\n",
    "                freq_pos[diff] += 1\n",
    "            else:\n",
    "                freq_neg[diff] += 1\n",
    "\n",
    "    freq_total = np.concatenate((freq_neg, freq_pos))\n",
    "    freq_total = freq_total/freq_total.sum()\n",
    "\n",
    "    diffs = []\n",
    "    for n in range(-80, 81):\n",
    "        diffs.append(n)\n",
    "\n",
    "    plt.bar(diffs[50:110], freq_total[50:110])\n",
    "    plt.title(\"Distribution of Actual-Prediction\")\n",
    "    plt.xlabel(\"Difference\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    print(\"+/- 1 years accuracy: {:.2f}%\".format(freq_total[79:81].sum()*100))\n",
    "    print(\"+/- 5 years accuracy: {:.2f}%\".format(freq_total[75:86].sum()*100))\n",
    "    print(\"+/- 10 years accuracy: {:.2f}%\".format(freq_total[70:91].sum()*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, batch_size=32, learning_rate=1e-5, num_epochs=5, starting_epoch=0):\n",
    "    torch.manual_seed(1000)\n",
    "    \n",
    "    train_loader, val_loader, test_loader = load_dataset(32)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().cuda()          \n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, val_loss, train_acc, val_acc = [], [], [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_epoch = 0\n",
    "        total_train_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = net(inputs.cuda())\n",
    "             \n",
    "            loss = criterion(outputs.cuda(), labels.long().cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            total_epoch += len(labels)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "\n",
    "        train_loss.append(float(total_train_loss)/total_epoch)\n",
    "        val_loss.append(evaluate(net, val_loader, criterion))\n",
    "        train_acc.append(get_accuracy(net, train_loader))\n",
    "        val_acc.append(get_accuracy(net, val_loader))\n",
    "            \n",
    "        print(\"Epoch: {}, Training Loss: {:.3f}, Validation Loss: {:.3f}, Training Accuracy: {:.3f}, Validation Accuracy: {:.3f}\"\n",
    "              .format(epoch+starting_epoch+1, train_loss[-1], val_loss[-1], train_acc[-1], val_acc[-1]))\n",
    "\n",
    "        model_path = get_model_name(\"VGG16\", batch_size, learning_rate, epoch+starting_epoch+1)\n",
    "        torch.save(net.state_dict(), model_path)    \n",
    "        np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
    "        np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)\n",
    "        np.savetxt(\"{}_train_acc.csv\".format(model_path), train_acc)\n",
    "        np.savetxt(\"{}_val_acc.csv\".format(model_path), val_acc)\n",
    "    \n",
    "    print('Finished Training')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curve(path, num_epochs, starting_epoch = 0):\n",
    "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
    "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
    "    train_acc = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
    "    val_acc = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
    "    \n",
    "    epochs = np.arange(1, num_epochs + 1 - starting_epoch)\n",
    "    \n",
    "    plt.title(\"Training vs. Validation Loss\")\n",
    "    plt.plot(epochs, train_loss, label=\"Train\")\n",
    "    plt.plot(epochs, val_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"Training vs Validation Accuracy\")\n",
    "    plt.plot(epochs, train_acc, label=\"Train\")\n",
    "    plt.plot(epochs, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_net(vgg16, batch_size=32, learning_rate=1e-5, num_epochs=10, starting_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_model_name(\"VGG16\", 32, 1e-5, 9)\n",
    "plot_training_curve(path, 9, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg16.load_state_dict(torch.load(get_model_name(\"VGG16\", 32, 1e-05, 6)))\n",
    "vgg16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = load_dataset(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(vgg16, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_off_accuracy(vgg16, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_off_accuracy(vgg16, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_off_accuracy(vgg16, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for image, label in test_loader:\n",
    "    img = image[0]\n",
    "    img = np.transpose(img, [1,2,0])\n",
    "    img = img / 2 + 0.5\n",
    "    plt.subplot(3, 5, k+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    k += 1\n",
    "    print(label[0]+1, np.round(predict(vgg16(image.cuda()))[0]))\n",
    "    if k > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
